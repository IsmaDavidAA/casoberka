{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65331d13-df1c-4609-81b5-d964b5e40646",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/IsmaDavidAA/casoberka/blob/main/Practica2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d0cb48-4dc9-44e1-9e96-35d224cdc053",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42lsiTXmQ5KX",
    "outputId": "05780d72-98ce-44a7-8ba9-7a4cafa692e1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8370835b-8664-47f0-aad6-7c9cc45a0914",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "343ebe4e-d00e-4830-959b-c69cf54b045e",
     "showTitle": false,
     "title": ""
    },
    "id": "sh8-pzPNRJFJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "path = \"/dbfs/FileStore/credit_card_candidate_churn_y_update_minable.csv\"\n",
    "df_berka = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92143a13-da23-47f1-acf2-6d65ef0a3f2d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WgBrE0NNRRLc",
    "outputId": "67df8985-b83f-430a-f9d0-a452ded6b164"
   },
   "outputs": [],
   "source": [
    "df_berka.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8037046d-79f6-4eae-a741-6492be78168c",
     "showTitle": false,
     "title": ""
    },
    "id": "lj_Ycvl4RY4w"
   },
   "source": [
    "onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9881237b-16c9-4f96-976f-2bb177bf9c6e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "GeSmgycdRa6L",
    "outputId": "b211b278-cd03-4fde-f0e1-170e432297eb"
   },
   "outputs": [],
   "source": [
    "# Selecciona las columnas categóricas\n",
    "categorical_columns = ['type', 'frequency', 'status', 'gender']\n",
    "quantitative_columns = ['account_creation', 'loan_date', 'amount', 'duration', 'payments', 'days_elapsed', 'adjusted_birth_number','age']\n",
    "# Extraer componentes de la fecha de nacimiento\n",
    "\n",
    "# Aplica One-Hot Encoding a las columnas categóricas\n",
    "df_encoded = pd.get_dummies(df_berka, columns=categorical_columns)\n",
    "scaler = StandardScaler()\n",
    "df_encoded[quantitative_columns] = scaler.fit_transform(df_encoded[quantitative_columns])\n",
    "# Muestra el nuevo DataFrame con One-Hot Encoding\n",
    "df_encoded = df_encoded.drop('birth_date', axis=1)\n",
    "df_encoded.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472b60de-c41e-4053-bbea-1a2ac4e90750",
     "showTitle": false,
     "title": ""
    },
    "id": "XL9J5PR1cLi5"
   },
   "source": [
    "#RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97eb6355-0b53-4144-a7eb-45080298ad2c",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "IgxdkkePcNCr",
    "outputId": "ff9c9c93-c0e3-462a-b2b6-db89d94196e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = df_encoded[['amount', 'duration', 'payments','days_elapsed']]\n",
    "y = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Random Forest con los datos preprocesados\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC del modelo: {roc_auc:.2f}\")\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con dos subplots en una fila\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Subplot 3: Matriz de Confusión\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b00381-128f-4cfa-953a-6d7757eed06c",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "cmd8uhzU8ehz",
    "outputId": "20086bfb-d95f-4bbb-c373-e009794af9a9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definir las características (X) y la variable objetivo (y)\n",
    "X = df_encoded[['amount', 'duration', 'payments', 'days_elapsed', 'type_OWNER',\n",
    "                'frequency_POPLATEK MESICNE', 'frequency_POPLATEK PO OBRATU',\n",
    "                'frequency_POPLATEK TYDNE', 'gender_Female', 'gender_Male']]\n",
    "y = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Random Forest con los datos preprocesados\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC del modelo: {roc_auc:.2f}\")\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con dos subplots en una fila\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "# Subplot 3: Matriz de Confusión\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ed5060-abfc-46eb-8d2a-6ac375923373",
     "showTitle": false,
     "title": ""
    },
    "id": "LrAdN_mofXpF"
   },
   "source": [
    "#REGRESION LOGISTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e36f02-693e-42db-b1f8-f1db1df273a0",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "ZtP-6kpvbsFQ",
    "outputId": "e849fe47-440a-4b50-a975-00c1464d9021"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = df_encoded[['amount', 'duration', 'payments','days_elapsed']]\n",
    "y = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Logística con los datos preprocesados\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob = logistic_model.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC del modelo: {roc_auc:.2f}\")\n",
    "# Calcula la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con tres subplots en una fila\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "# Subplot 3: Histograma de probabilidades\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_prob[y_test == 1], bins=30, color='blue', alpha=0.5, label='Positivos', density=True)\n",
    "plt.hist(y_prob[y_test == 0], bins=30, color='red', alpha=0.5, label='Negativos', density=True)\n",
    "plt.xlabel('Probabilidad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Probabilidades')\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c64836f-b3c6-4674-a040-67b33bb8603d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "jpfYVwr2-qGK",
    "outputId": "a96fed84-999a-4000-8571-8b394f020990"
   },
   "outputs": [],
   "source": [
    "# Selecciona las columnas categóricas\n",
    "X_categorical = df_encoded[['amount', 'duration', 'payments', 'days_elapsed', 'type_OWNER',\n",
    "                'frequency_POPLATEK MESICNE', 'frequency_POPLATEK PO OBRATU',\n",
    "                'frequency_POPLATEK TYDNE', 'gender_Female', 'gender_Male']]\n",
    "y_categorical = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train_categorical, X_test_categorical, y_train_categorical, y_test_categorical = train_test_split(\n",
    "    X_categorical, y_categorical, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Logística con los datos preprocesados\n",
    "logistic_model_categorical = LogisticRegression(random_state=42)\n",
    "logistic_model_categorical.fit(X_train_categorical, y_train_categorical)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_categorical = logistic_model_categorical.predict(X_test_categorical)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy_categorical = accuracy_score(y_test_categorical, y_pred_categorical)\n",
    "print(f\"Precisión del modelo con variables categóricas: {accuracy_categorical:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob_categorical = logistic_model_categorical.predict_proba(X_test_categorical)[:, 1]\n",
    "roc_auc_categorical = roc_auc_score(y_test_categorical, y_prob_categorical)\n",
    "print(f\"AUC del modelo con variables categóricas: {roc_auc_categorical:.2f}\")\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con tres subplots en una fila\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "# Subplot 3: Histograma de probabilidades\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_prob[y_test == 1], bins=30, color='blue', alpha=0.5, label='Positivos', density=True)\n",
    "plt.hist(y_prob[y_test == 0], bins=30, color='red', alpha=0.5, label='Negativos', density=True)\n",
    "plt.xlabel('Probabilidad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Probabilidades')\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bebd9aa8-b552-47f1-bd4e-e84e32f43693",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "TLCspxfpZ-Xv",
    "outputId": "4f135132-fc11-4ac2-d69c-a5b8a9b5d665"
   },
   "outputs": [],
   "source": [
    "# Selecciona todas las columnas excepto \"churn_y\" en X\n",
    "X_all_features = df_encoded.drop(['status_A', 'status_B', 'status_C',\n",
    "                'status_D', \"churn_y\", \"gender_Female\", \"gender_Male\", \"adjusted_birth_number\", \"age\"], axis=1)\n",
    "y_all_features = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train_all_features, X_test_all_features, y_train_all_features, y_test_all_features = train_test_split(\n",
    "    X_all_features, y_all_features, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Logística con todas las características\n",
    "logistic_model_all_features = LogisticRegression(random_state=42)\n",
    "logistic_model_all_features.fit(X_train_all_features, y_train_all_features)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_all_features = logistic_model_all_features.predict(X_test_all_features)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy_all_features = accuracy_score(y_test_all_features, y_pred_all_features)\n",
    "print(f\"Precisión del modelo con todas las variables: {accuracy_all_features:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob_all_features = logistic_model_all_features.predict_proba(X_test_all_features)[:, 1]\n",
    "roc_auc_all_features = roc_auc_score(y_test_all_features, y_prob_all_features)\n",
    "print(f\"AUC del modelo con todas las variables: {roc_auc_all_features:.2f}\")\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con tres subplots en una fila\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "# Subplot 3: Histograma de probabilidades\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_prob[y_test == 1], bins=30, color='blue', alpha=0.5, label='Positivos', density=True)\n",
    "plt.hist(y_prob[y_test == 0], bins=30, color='red', alpha=0.5, label='Negativos', density=True)\n",
    "plt.xlabel('Probabilidad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Probabilidades')\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b06f340-a13a-4ae6-8a0c-713af1cf15f1",
     "showTitle": false,
     "title": ""
    },
    "id": "Mw-XIHQ-t7W-"
   },
   "source": [
    "#ARBOL DE DECISIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead8b9a9-db1d-4b76-a0fd-fdba1f8adc2f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "905KGGsQt9q2",
    "outputId": "72fb46e1-2c12-425e-a105-bf1e5665fbc7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = df_encoded[['amount', 'duration', 'payments', 'days_elapsed']]\n",
    "y = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "# Crear y entrenar el modelo de Árbol de Decisiones con los datos preprocesados\n",
    "tree_model = DecisionTreeClassifier(random_state=22)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob = tree_model.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC del modelo: {roc_auc:.2f}\")\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con tres subplots en una fila\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "# Subplot 3: Histograma de probabilidades\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_prob[y_test == 1], bins=30, color='blue', alpha=0.5, label='Positivos', density=True)\n",
    "plt.hist(y_prob[y_test == 0], bins=30, color='red', alpha=0.5, label='Negativos', density=True)\n",
    "plt.xlabel('Probabilidad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Probabilidades')\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76926f8d-4099-47f9-b223-ceded7930e11",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "XqfYRv-Wu6Ee",
    "outputId": "76862bc5-e152-4d85-8686-6753de80c4b3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = df_encoded[['amount', 'duration', 'payments', 'days_elapsed']]\n",
    "y = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Máquinas de Vectores de Soporte (SVM) con los datos preprocesados\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob = svm_model.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC del modelo: {roc_auc:.2f}\")\n",
    "# Calcula la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calcula la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Crea una figura con tres subplots en una fila\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Curva ROC\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Subplot 2: Curva Precision-Recall\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "# Subplot 3: Histograma de probabilidades\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_prob[y_test == 1], bins=30, color='blue', alpha=0.5, label='Positivos', density=True)\n",
    "plt.hist(y_prob[y_test == 0], bins=30, color='red', alpha=0.5, label='Negativos', density=True)\n",
    "plt.xlabel('Probabilidad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Probabilidades')\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b93cb6e6-da0a-4ce3-abea-4dd794e07f23",
     "showTitle": false,
     "title": ""
    },
    "id": "WkndtF8WvknD"
   },
   "source": [
    "#Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e408890-4236-4c18-a980-efa99a77a77e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pLdYC25HvlXN",
    "outputId": "361c6a9c-5903-41b9-c410-63d91ac828a5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = df_encoded[['amount', 'duration', 'payments', 'days_elapsed']]\n",
    "y = df_encoded[\"churn_y\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.28, random_state=42)\n",
    "\n",
    "# Normalizar las características (escalar)\n",
    "scaler = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "scaler.adapt(X_train)\n",
    "\n",
    "# Crear y entrenar el modelo de Redes Neuronales Artificiales (ANN)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Calcular el AUC (Área bajo la curva ROC) del modelo\n",
    "y_prob = model.predict(X_test).flatten()  # Probabilidad de clase positiva\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC del modelo: {roc_auc:.2f}\")\n",
    "\n",
    "# Calcular la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Crear la figura\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calcular la curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Histograma de probabilidades positivas (clase positiva)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "\n",
    "# Graficar la curva Precision-Recall\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.step(recall, precision, color='b', alpha=0.5, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Curva Precision-Recall (AP={0:0.2f})'.format(average_precision))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Practica2",
   "widgets": {}
  },
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
